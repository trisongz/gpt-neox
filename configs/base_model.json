{
  "num_epochs": 10,
  "vocab_size": null,
  "batch_size": 4,
  "learning_rate": 1e-4,
  "validate_every": 100,
  "generate_every": 500,
  "generate_length": 256,
  "seq_len": 256,
  "hidden_dim": 512,
  "n_layers": 6,
  "n_heads": 8,
  "dim_head": 64,
  "tokenizer": {
    "type": "hf_gp2tokenizer",
    "from_pretrained": true,
    "add_padding_token": true
  }
}